{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy\n",
    "import tensorflow\n",
    "import torch\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate  ,SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Sequential \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(x,y,ratio) :\n",
    "    in_out = []\n",
    "    \n",
    "    p_xy = [] \n",
    "    n_xy=[]\n",
    "    \n",
    "    for i in range( len(x) ) :\n",
    "        if y[i]== 0 :\n",
    "            n_xy.append( [x[i],y[i]] )\n",
    "        else :\n",
    "            p_xy.append( [ x[i] , y[i] ] )\n",
    "    \n",
    "    \n",
    "    print(\"debugging meassage -   negative \",len(n_xy)  , \" postivie \",len(p_xy))\n",
    "    \n",
    "  \n",
    "    a=random.shuffle( p_xy )\n",
    "    b=random.shuffle( n_xy )\n",
    "    print(\"debugging message  types \", type(a), type(b))\n",
    "    \n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range( len(n_xy )) :\n",
    "        if i < int(len(n_xy)*ratio) :\n",
    "            x_train.append( n_xy[i][0] )\n",
    "            y_train.append( n_xy[i][1] )\n",
    "        else :\n",
    "            x_val.append( n_xy[i][0] )\n",
    "            y_val.append( n_xy[i][1] )\n",
    "    \n",
    "    for i in range( len(p_xy) ) :\n",
    "        if i < int( len(p_xy) * ratio ) :\n",
    "            x_train.append( p_xy[i][0] )\n",
    "            y_train.append( p_xy[i][1] )\n",
    "        else :\n",
    "            x_val.append( p_xy[i][0] )\n",
    "            y_val.append( p_xy[i][1] )\n",
    "    \n",
    "    \n",
    "    return [x_train,y_train,x_val,y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  visualize( x , y ) :\n",
    "    \n",
    "    t=150\n",
    "    d=20\n",
    "    \n",
    "    frq_n = numpy.zeros( [t] ) \n",
    "    frq_p = numpy.zeros( [t] )\n",
    "    frq_t = numpy.zeros( [t] )\n",
    "    \n",
    "    \n",
    "    \n",
    "    length_list=[]\n",
    "    lens=d\n",
    "    \n",
    "    while(lens<=d*t) :\n",
    "        length_list.append( lens )\n",
    "        lens = lens + d\n",
    "    n_p=0\n",
    "    n_n=0\n",
    "    print(len(length_list))\n",
    "    for i in range( len(x) ) :\n",
    "        length = len( x[i] )\n",
    "        index = int(length/d)\n",
    "        if y[i]== 0  :\n",
    "            n_n=n_n+1\n",
    "            frq_n[index] = frq_n[index]+1\n",
    "        else :\n",
    "            n_p=n_p+1\n",
    "            frq_p[index] = frq_p[index]+1\n",
    "            \n",
    "    frq_t = frq_p + frq_n\n",
    "         \n",
    "    sum_n=0\n",
    "    sum_p=0\n",
    "    print(\"positive sample \",n_p,\" negative sample \",n_n)\n",
    "    for i in range(t) :\n",
    "        sum_n = sum_n + frq_n[i]\n",
    "        sum_p = sum_p + frq_p[i]\n",
    "        print(  i,length_list[i]  , sum_n/n_n , sum_p/n_p ,( sum_n + sum_p )/(n_n+n_p) )\n",
    "    \n",
    "    plt.plot( length_list , frq_p , color= 'red' )\n",
    "    plt.plot( length_list , frq_n , color = 'green' )\n",
    "    plt.plot( length_list , frq_t , color = 'blue' )\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    return [ frq_n , frq_p , frq_t ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading pretrained word2vec  ' trained by negative subsampling '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting words for which embedding is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naman/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "vocab_word2vec = word2vec.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "details about training and validation sets combined\n",
      "number of negative reviews  12500\n",
      "positive review s 12500\n",
      "details on test set\n",
      "number of negative reviews  12500\n",
      "positive review s 12500\n"
     ]
    }
   ],
   "source": [
    "from loader import stanford_train , stanford_test\n",
    "print(\"details about training and validation sets combined\")\n",
    "[x_train_val,y_train_val,c] = stanford_train()\n",
    "print(\"details on test set\")\n",
    "[x_test,y_test,c] =  stanford_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = x_train_val + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'br': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " 'film': 19,\n",
       " 'on': 20,\n",
       " 'not': 21,\n",
       " 'you': 22,\n",
       " 'are': 23,\n",
       " 'his': 24,\n",
       " 'have': 25,\n",
       " 'be': 26,\n",
       " 'one': 27,\n",
       " 'he': 28,\n",
       " 'all': 29,\n",
       " 'at': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'so': 34,\n",
       " 'who': 35,\n",
       " 'from': 36,\n",
       " 'like': 37,\n",
       " 'or': 38,\n",
       " 'just': 39,\n",
       " 'her': 40,\n",
       " 'out': 41,\n",
       " 'about': 42,\n",
       " 'if': 43,\n",
       " \"it's\": 44,\n",
       " 'has': 45,\n",
       " 'there': 46,\n",
       " 'some': 47,\n",
       " 'what': 48,\n",
       " 'good': 49,\n",
       " 'when': 50,\n",
       " 'more': 51,\n",
       " 'very': 52,\n",
       " 'up': 53,\n",
       " 'no': 54,\n",
       " 'time': 55,\n",
       " 'my': 56,\n",
       " 'even': 57,\n",
       " 'would': 58,\n",
       " 'she': 59,\n",
       " 'which': 60,\n",
       " 'only': 61,\n",
       " 'really': 62,\n",
       " 'see': 63,\n",
       " 'story': 64,\n",
       " 'their': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'me': 68,\n",
       " 'well': 69,\n",
       " 'were': 70,\n",
       " 'than': 71,\n",
       " 'much': 72,\n",
       " 'we': 73,\n",
       " 'bad': 74,\n",
       " 'been': 75,\n",
       " 'get': 76,\n",
       " 'do': 77,\n",
       " 'great': 78,\n",
       " 'other': 79,\n",
       " 'will': 80,\n",
       " 'also': 81,\n",
       " 'into': 82,\n",
       " 'people': 83,\n",
       " 'because': 84,\n",
       " 'how': 85,\n",
       " 'first': 86,\n",
       " 'him': 87,\n",
       " 'most': 88,\n",
       " \"don't\": 89,\n",
       " 'made': 90,\n",
       " 'then': 91,\n",
       " 'its': 92,\n",
       " 'them': 93,\n",
       " 'make': 94,\n",
       " 'way': 95,\n",
       " 'too': 96,\n",
       " 'movies': 97,\n",
       " 'could': 98,\n",
       " 'any': 99,\n",
       " 'after': 100,\n",
       " 'think': 101,\n",
       " 'characters': 102,\n",
       " 'watch': 103,\n",
       " 'films': 104,\n",
       " 'two': 105,\n",
       " 'many': 106,\n",
       " 'seen': 107,\n",
       " 'character': 108,\n",
       " 'being': 109,\n",
       " 'never': 110,\n",
       " 'plot': 111,\n",
       " 'love': 112,\n",
       " 'acting': 113,\n",
       " 'life': 114,\n",
       " 'did': 115,\n",
       " 'best': 116,\n",
       " 'where': 117,\n",
       " 'know': 118,\n",
       " 'show': 119,\n",
       " 'little': 120,\n",
       " 'over': 121,\n",
       " 'off': 122,\n",
       " 'ever': 123,\n",
       " 'does': 124,\n",
       " 'your': 125,\n",
       " 'better': 126,\n",
       " 'end': 127,\n",
       " 'man': 128,\n",
       " 'scene': 129,\n",
       " 'still': 130,\n",
       " 'say': 131,\n",
       " 'these': 132,\n",
       " 'here': 133,\n",
       " 'why': 134,\n",
       " 'scenes': 135,\n",
       " 'while': 136,\n",
       " 'something': 137,\n",
       " 'such': 138,\n",
       " 'go': 139,\n",
       " 'through': 140,\n",
       " 'back': 141,\n",
       " 'should': 142,\n",
       " 'those': 143,\n",
       " 'real': 144,\n",
       " \"i'm\": 145,\n",
       " 'now': 146,\n",
       " 'watching': 147,\n",
       " 'thing': 148,\n",
       " \"doesn't\": 149,\n",
       " 'actors': 150,\n",
       " 'though': 151,\n",
       " 'funny': 152,\n",
       " 'years': 153,\n",
       " \"didn't\": 154,\n",
       " 'old': 155,\n",
       " 'another': 156,\n",
       " '10': 157,\n",
       " 'work': 158,\n",
       " 'before': 159,\n",
       " 'actually': 160,\n",
       " 'nothing': 161,\n",
       " 'makes': 162,\n",
       " 'look': 163,\n",
       " 'director': 164,\n",
       " 'find': 165,\n",
       " 'going': 166,\n",
       " 'same': 167,\n",
       " 'new': 168,\n",
       " 'lot': 169,\n",
       " 'every': 170,\n",
       " 'few': 171,\n",
       " 'again': 172,\n",
       " 'part': 173,\n",
       " 'cast': 174,\n",
       " 'down': 175,\n",
       " 'us': 176,\n",
       " 'things': 177,\n",
       " 'want': 178,\n",
       " 'quite': 179,\n",
       " 'pretty': 180,\n",
       " 'world': 181,\n",
       " 'horror': 182,\n",
       " 'around': 183,\n",
       " 'seems': 184,\n",
       " \"can't\": 185,\n",
       " 'young': 186,\n",
       " 'take': 187,\n",
       " 'however': 188,\n",
       " 'got': 189,\n",
       " 'thought': 190,\n",
       " 'big': 191,\n",
       " 'fact': 192,\n",
       " 'enough': 193,\n",
       " 'long': 194,\n",
       " 'both': 195,\n",
       " \"that's\": 196,\n",
       " 'give': 197,\n",
       " \"i've\": 198,\n",
       " 'own': 199,\n",
       " 'may': 200,\n",
       " 'between': 201,\n",
       " 'comedy': 202,\n",
       " 'right': 203,\n",
       " 'series': 204,\n",
       " 'action': 205,\n",
       " 'must': 206,\n",
       " 'music': 207,\n",
       " 'without': 208,\n",
       " 'times': 209,\n",
       " 'saw': 210,\n",
       " 'always': 211,\n",
       " 'original': 212,\n",
       " \"isn't\": 213,\n",
       " 'role': 214,\n",
       " 'come': 215,\n",
       " 'almost': 216,\n",
       " 'gets': 217,\n",
       " 'interesting': 218,\n",
       " 'guy': 219,\n",
       " 'point': 220,\n",
       " 'done': 221,\n",
       " \"there's\": 222,\n",
       " 'whole': 223,\n",
       " 'least': 224,\n",
       " 'far': 225,\n",
       " 'bit': 226,\n",
       " 'script': 227,\n",
       " 'minutes': 228,\n",
       " 'feel': 229,\n",
       " '2': 230,\n",
       " 'anything': 231,\n",
       " 'making': 232,\n",
       " 'might': 233,\n",
       " 'since': 234,\n",
       " 'am': 235,\n",
       " 'family': 236,\n",
       " \"he's\": 237,\n",
       " 'last': 238,\n",
       " 'probably': 239,\n",
       " 'tv': 240,\n",
       " 'performance': 241,\n",
       " 'kind': 242,\n",
       " 'away': 243,\n",
       " 'yet': 244,\n",
       " 'fun': 245,\n",
       " 'worst': 246,\n",
       " 'sure': 247,\n",
       " 'rather': 248,\n",
       " 'hard': 249,\n",
       " 'girl': 250,\n",
       " 'anyone': 251,\n",
       " 'each': 252,\n",
       " 'played': 253,\n",
       " 'day': 254,\n",
       " 'found': 255,\n",
       " 'looking': 256,\n",
       " 'woman': 257,\n",
       " 'screen': 258,\n",
       " 'although': 259,\n",
       " 'our': 260,\n",
       " 'especially': 261,\n",
       " 'believe': 262,\n",
       " 'having': 263,\n",
       " 'trying': 264,\n",
       " 'course': 265,\n",
       " 'dvd': 266,\n",
       " 'everything': 267,\n",
       " 'set': 268,\n",
       " 'goes': 269,\n",
       " 'comes': 270,\n",
       " 'put': 271,\n",
       " 'ending': 272,\n",
       " 'maybe': 273,\n",
       " 'place': 274,\n",
       " 'book': 275,\n",
       " 'shows': 276,\n",
       " 'three': 277,\n",
       " 'worth': 278,\n",
       " 'different': 279,\n",
       " 'main': 280,\n",
       " 'once': 281,\n",
       " 'sense': 282,\n",
       " 'american': 283,\n",
       " 'reason': 284,\n",
       " 'looks': 285,\n",
       " 'effects': 286,\n",
       " 'watched': 287,\n",
       " 'play': 288,\n",
       " 'true': 289,\n",
       " 'money': 290,\n",
       " 'actor': 291,\n",
       " \"wasn't\": 292,\n",
       " 'job': 293,\n",
       " 'together': 294,\n",
       " 'war': 295,\n",
       " 'someone': 296,\n",
       " 'plays': 297,\n",
       " 'instead': 298,\n",
       " 'high': 299,\n",
       " 'during': 300,\n",
       " 'year': 301,\n",
       " 'said': 302,\n",
       " 'half': 303,\n",
       " 'everyone': 304,\n",
       " 'later': 305,\n",
       " 'takes': 306,\n",
       " '1': 307,\n",
       " 'seem': 308,\n",
       " 'audience': 309,\n",
       " 'special': 310,\n",
       " 'beautiful': 311,\n",
       " 'left': 312,\n",
       " 'himself': 313,\n",
       " 'seeing': 314,\n",
       " 'john': 315,\n",
       " 'night': 316,\n",
       " 'black': 317,\n",
       " 'version': 318,\n",
       " 'shot': 319,\n",
       " 'excellent': 320,\n",
       " 'idea': 321,\n",
       " 'house': 322,\n",
       " 'mind': 323,\n",
       " 'star': 324,\n",
       " 'wife': 325,\n",
       " 'fan': 326,\n",
       " 'death': 327,\n",
       " 'used': 328,\n",
       " 'else': 329,\n",
       " 'simply': 330,\n",
       " 'nice': 331,\n",
       " 'budget': 332,\n",
       " 'poor': 333,\n",
       " 'short': 334,\n",
       " 'completely': 335,\n",
       " 'second': 336,\n",
       " \"you're\": 337,\n",
       " '3': 338,\n",
       " 'read': 339,\n",
       " 'less': 340,\n",
       " 'along': 341,\n",
       " 'top': 342,\n",
       " 'help': 343,\n",
       " 'home': 344,\n",
       " 'men': 345,\n",
       " 'either': 346,\n",
       " 'line': 347,\n",
       " 'boring': 348,\n",
       " 'dead': 349,\n",
       " 'friends': 350,\n",
       " 'kids': 351,\n",
       " 'try': 352,\n",
       " 'production': 353,\n",
       " 'enjoy': 354,\n",
       " 'camera': 355,\n",
       " 'use': 356,\n",
       " 'wrong': 357,\n",
       " 'given': 358,\n",
       " 'low': 359,\n",
       " 'classic': 360,\n",
       " 'father': 361,\n",
       " 'need': 362,\n",
       " 'full': 363,\n",
       " 'stupid': 364,\n",
       " 'until': 365,\n",
       " 'next': 366,\n",
       " 'performances': 367,\n",
       " 'school': 368,\n",
       " 'hollywood': 369,\n",
       " 'rest': 370,\n",
       " 'truly': 371,\n",
       " 'awful': 372,\n",
       " 'video': 373,\n",
       " 'couple': 374,\n",
       " 'start': 375,\n",
       " 'sex': 376,\n",
       " 'recommend': 377,\n",
       " 'women': 378,\n",
       " 'let': 379,\n",
       " 'tell': 380,\n",
       " 'terrible': 381,\n",
       " 'remember': 382,\n",
       " 'mean': 383,\n",
       " 'came': 384,\n",
       " 'getting': 385,\n",
       " 'understand': 386,\n",
       " 'perhaps': 387,\n",
       " 'moments': 388,\n",
       " 'name': 389,\n",
       " 'keep': 390,\n",
       " 'face': 391,\n",
       " 'itself': 392,\n",
       " 'wonderful': 393,\n",
       " 'playing': 394,\n",
       " 'human': 395,\n",
       " 'style': 396,\n",
       " 'small': 397,\n",
       " 'episode': 398,\n",
       " 'perfect': 399,\n",
       " 'others': 400,\n",
       " 'person': 401,\n",
       " 'doing': 402,\n",
       " 'often': 403,\n",
       " 'early': 404,\n",
       " 'stars': 405,\n",
       " 'definitely': 406,\n",
       " 'written': 407,\n",
       " 'head': 408,\n",
       " 'lines': 409,\n",
       " 'dialogue': 410,\n",
       " 'gives': 411,\n",
       " 'piece': 412,\n",
       " \"couldn't\": 413,\n",
       " 'went': 414,\n",
       " 'finally': 415,\n",
       " 'mother': 416,\n",
       " 'case': 417,\n",
       " 'title': 418,\n",
       " 'absolutely': 419,\n",
       " 'live': 420,\n",
       " 'boy': 421,\n",
       " 'yes': 422,\n",
       " 'laugh': 423,\n",
       " 'certainly': 424,\n",
       " 'liked': 425,\n",
       " 'become': 426,\n",
       " 'worse': 427,\n",
       " 'entertaining': 428,\n",
       " 'oh': 429,\n",
       " 'sort': 430,\n",
       " 'loved': 431,\n",
       " 'lost': 432,\n",
       " 'hope': 433,\n",
       " 'called': 434,\n",
       " 'picture': 435,\n",
       " 'felt': 436,\n",
       " 'overall': 437,\n",
       " 'entire': 438,\n",
       " 'mr': 439,\n",
       " 'several': 440,\n",
       " 'based': 441,\n",
       " 'supposed': 442,\n",
       " 'cinema': 443,\n",
       " 'friend': 444,\n",
       " 'guys': 445,\n",
       " 'sound': 446,\n",
       " '5': 447,\n",
       " 'problem': 448,\n",
       " 'drama': 449,\n",
       " 'against': 450,\n",
       " 'waste': 451,\n",
       " 'white': 452,\n",
       " 'beginning': 453,\n",
       " '4': 454,\n",
       " 'fans': 455,\n",
       " 'totally': 456,\n",
       " 'dark': 457,\n",
       " 'care': 458,\n",
       " 'direction': 459,\n",
       " 'humor': 460,\n",
       " 'wanted': 461,\n",
       " \"she's\": 462,\n",
       " 'seemed': 463,\n",
       " 'under': 464,\n",
       " 'game': 465,\n",
       " 'children': 466,\n",
       " 'despite': 467,\n",
       " 'lives': 468,\n",
       " 'lead': 469,\n",
       " 'guess': 470,\n",
       " 'example': 471,\n",
       " 'already': 472,\n",
       " 'final': 473,\n",
       " 'throughout': 474,\n",
       " \"you'll\": 475,\n",
       " 'evil': 476,\n",
       " 'turn': 477,\n",
       " 'becomes': 478,\n",
       " 'unfortunately': 479,\n",
       " 'able': 480,\n",
       " 'quality': 481,\n",
       " \"i'd\": 482,\n",
       " 'days': 483,\n",
       " 'history': 484,\n",
       " 'fine': 485,\n",
       " 'side': 486,\n",
       " 'wants': 487,\n",
       " 'heart': 488,\n",
       " 'horrible': 489,\n",
       " 'writing': 490,\n",
       " 'amazing': 491,\n",
       " 'b': 492,\n",
       " 'flick': 493,\n",
       " 'killer': 494,\n",
       " 'run': 495,\n",
       " 'son': 496,\n",
       " '\\x96': 497,\n",
       " 'michael': 498,\n",
       " 'works': 499,\n",
       " 'close': 500,\n",
       " \"they're\": 501,\n",
       " 'act': 502,\n",
       " 'art': 503,\n",
       " 'kill': 504,\n",
       " 'matter': 505,\n",
       " 'etc': 506,\n",
       " 'tries': 507,\n",
       " \"won't\": 508,\n",
       " 'past': 509,\n",
       " 'town': 510,\n",
       " 'enjoyed': 511,\n",
       " 'turns': 512,\n",
       " 'brilliant': 513,\n",
       " 'gave': 514,\n",
       " 'behind': 515,\n",
       " 'parts': 516,\n",
       " 'stuff': 517,\n",
       " 'genre': 518,\n",
       " 'eyes': 519,\n",
       " 'car': 520,\n",
       " 'favorite': 521,\n",
       " 'directed': 522,\n",
       " 'late': 523,\n",
       " 'hand': 524,\n",
       " 'expect': 525,\n",
       " 'soon': 526,\n",
       " 'hour': 527,\n",
       " 'obviously': 528,\n",
       " 'themselves': 529,\n",
       " 'sometimes': 530,\n",
       " 'killed': 531,\n",
       " 'thinking': 532,\n",
       " 'actress': 533,\n",
       " 'child': 534,\n",
       " 'girls': 535,\n",
       " 'viewer': 536,\n",
       " 'starts': 537,\n",
       " 'city': 538,\n",
       " 'myself': 539,\n",
       " 'decent': 540,\n",
       " 'highly': 541,\n",
       " 'stop': 542,\n",
       " 'type': 543,\n",
       " 'self': 544,\n",
       " 'god': 545,\n",
       " 'says': 546,\n",
       " 'group': 547,\n",
       " 'anyway': 548,\n",
       " 'voice': 549,\n",
       " 'took': 550,\n",
       " 'known': 551,\n",
       " 'blood': 552,\n",
       " 'kid': 553,\n",
       " 'heard': 554,\n",
       " 'happens': 555,\n",
       " 'except': 556,\n",
       " 'fight': 557,\n",
       " 'feeling': 558,\n",
       " 'experience': 559,\n",
       " 'coming': 560,\n",
       " 'slow': 561,\n",
       " 'daughter': 562,\n",
       " 'writer': 563,\n",
       " 'stories': 564,\n",
       " 'moment': 565,\n",
       " 'leave': 566,\n",
       " 'told': 567,\n",
       " 'extremely': 568,\n",
       " 'score': 569,\n",
       " 'violence': 570,\n",
       " 'police': 571,\n",
       " 'involved': 572,\n",
       " 'strong': 573,\n",
       " 'lack': 574,\n",
       " 'chance': 575,\n",
       " 'cannot': 576,\n",
       " 'hit': 577,\n",
       " 'roles': 578,\n",
       " 'hilarious': 579,\n",
       " 's': 580,\n",
       " 'happen': 581,\n",
       " 'wonder': 582,\n",
       " 'particularly': 583,\n",
       " 'ok': 584,\n",
       " 'including': 585,\n",
       " 'living': 586,\n",
       " 'save': 587,\n",
       " 'looked': 588,\n",
       " \"wouldn't\": 589,\n",
       " 'crap': 590,\n",
       " 'please': 591,\n",
       " 'simple': 592,\n",
       " 'cool': 593,\n",
       " 'murder': 594,\n",
       " 'obvious': 595,\n",
       " 'happened': 596,\n",
       " 'complete': 597,\n",
       " 'cut': 598,\n",
       " 'age': 599,\n",
       " 'serious': 600,\n",
       " 'gore': 601,\n",
       " 'attempt': 602,\n",
       " 'hell': 603,\n",
       " 'ago': 604,\n",
       " 'song': 605,\n",
       " 'shown': 606,\n",
       " 'taken': 607,\n",
       " 'english': 608,\n",
       " 'james': 609,\n",
       " 'robert': 610,\n",
       " 'david': 611,\n",
       " 'seriously': 612,\n",
       " 'released': 613,\n",
       " 'reality': 614,\n",
       " 'opening': 615,\n",
       " 'interest': 616,\n",
       " 'jokes': 617,\n",
       " 'across': 618,\n",
       " 'none': 619,\n",
       " 'hero': 620,\n",
       " 'possible': 621,\n",
       " 'exactly': 622,\n",
       " 'today': 623,\n",
       " 'alone': 624,\n",
       " 'sad': 625,\n",
       " 'brother': 626,\n",
       " 'number': 627,\n",
       " 'career': 628,\n",
       " 'saying': 629,\n",
       " \"film's\": 630,\n",
       " 'hours': 631,\n",
       " 'usually': 632,\n",
       " 'cinematography': 633,\n",
       " 'talent': 634,\n",
       " 'view': 635,\n",
       " 'annoying': 636,\n",
       " 'yourself': 637,\n",
       " 'running': 638,\n",
       " 'relationship': 639,\n",
       " 'documentary': 640,\n",
       " 'wish': 641,\n",
       " 'order': 642,\n",
       " 'huge': 643,\n",
       " 'shots': 644,\n",
       " 'whose': 645,\n",
       " 'ridiculous': 646,\n",
       " 'taking': 647,\n",
       " 'important': 648,\n",
       " 'light': 649,\n",
       " 'body': 650,\n",
       " 'middle': 651,\n",
       " 'level': 652,\n",
       " 'ends': 653,\n",
       " 'started': 654,\n",
       " 'call': 655,\n",
       " 'female': 656,\n",
       " \"i'll\": 657,\n",
       " 'husband': 658,\n",
       " 'four': 659,\n",
       " 'power': 660,\n",
       " 'turned': 661,\n",
       " 'word': 662,\n",
       " 'major': 663,\n",
       " 'opinion': 664,\n",
       " 'change': 665,\n",
       " 'mostly': 666,\n",
       " 'usual': 667,\n",
       " 'silly': 668,\n",
       " 'scary': 669,\n",
       " 'rating': 670,\n",
       " 'beyond': 671,\n",
       " 'somewhat': 672,\n",
       " 'happy': 673,\n",
       " 'ones': 674,\n",
       " 'words': 675,\n",
       " 'room': 676,\n",
       " 'knows': 677,\n",
       " 'knew': 678,\n",
       " 'country': 679,\n",
       " 'disappointed': 680,\n",
       " 'talking': 681,\n",
       " 'novel': 682,\n",
       " 'apparently': 683,\n",
       " 'non': 684,\n",
       " 'strange': 685,\n",
       " 'upon': 686,\n",
       " 'attention': 687,\n",
       " 'finds': 688,\n",
       " 'single': 689,\n",
       " 'basically': 690,\n",
       " 'cheap': 691,\n",
       " 'modern': 692,\n",
       " 'due': 693,\n",
       " 'jack': 694,\n",
       " 'musical': 695,\n",
       " 'television': 696,\n",
       " 'problems': 697,\n",
       " 'miss': 698,\n",
       " 'episodes': 699,\n",
       " 'clearly': 700,\n",
       " 'local': 701,\n",
       " '7': 702,\n",
       " 'british': 703,\n",
       " 'thriller': 704,\n",
       " 'talk': 705,\n",
       " 'events': 706,\n",
       " 'sequence': 707,\n",
       " 'five': 708,\n",
       " \"aren't\": 709,\n",
       " 'class': 710,\n",
       " 'french': 711,\n",
       " 'moving': 712,\n",
       " 'ten': 713,\n",
       " 'fast': 714,\n",
       " 'earth': 715,\n",
       " 'review': 716,\n",
       " 'tells': 717,\n",
       " 'predictable': 718,\n",
       " 'songs': 719,\n",
       " 'team': 720,\n",
       " 'comic': 721,\n",
       " 'straight': 722,\n",
       " 'whether': 723,\n",
       " '8': 724,\n",
       " 'die': 725,\n",
       " 'add': 726,\n",
       " 'dialog': 727,\n",
       " 'entertainment': 728,\n",
       " 'above': 729,\n",
       " 'sets': 730,\n",
       " 'future': 731,\n",
       " 'enjoyable': 732,\n",
       " 'appears': 733,\n",
       " 'near': 734,\n",
       " 'space': 735,\n",
       " 'easily': 736,\n",
       " 'hate': 737,\n",
       " 'soundtrack': 738,\n",
       " 'bring': 739,\n",
       " 'giving': 740,\n",
       " 'lots': 741,\n",
       " 'similar': 742,\n",
       " 'romantic': 743,\n",
       " 'george': 744,\n",
       " 'supporting': 745,\n",
       " 'release': 746,\n",
       " 'mention': 747,\n",
       " 'filmed': 748,\n",
       " 'within': 749,\n",
       " 'message': 750,\n",
       " 'sequel': 751,\n",
       " 'clear': 752,\n",
       " 'falls': 753,\n",
       " 'needs': 754,\n",
       " \"haven't\": 755,\n",
       " 'dull': 756,\n",
       " 'suspense': 757,\n",
       " 'bunch': 758,\n",
       " 'eye': 759,\n",
       " 'surprised': 760,\n",
       " 'showing': 761,\n",
       " 'tried': 762,\n",
       " 'sorry': 763,\n",
       " 'certain': 764,\n",
       " 'working': 765,\n",
       " 'easy': 766,\n",
       " 'ways': 767,\n",
       " 'theme': 768,\n",
       " 'theater': 769,\n",
       " 'among': 770,\n",
       " 'named': 771,\n",
       " \"what's\": 772,\n",
       " 'storyline': 773,\n",
       " 'monster': 774,\n",
       " 'king': 775,\n",
       " 'stay': 776,\n",
       " 'effort': 777,\n",
       " 'minute': 778,\n",
       " 'fall': 779,\n",
       " 'stand': 780,\n",
       " 'gone': 781,\n",
       " 'rock': 782,\n",
       " 'using': 783,\n",
       " '9': 784,\n",
       " 'feature': 785,\n",
       " 'buy': 786,\n",
       " 'comments': 787,\n",
       " \"'\": 788,\n",
       " 'typical': 789,\n",
       " 't': 790,\n",
       " 'sister': 791,\n",
       " 'editing': 792,\n",
       " 'avoid': 793,\n",
       " 'tale': 794,\n",
       " 'deal': 795,\n",
       " 'dr': 796,\n",
       " 'mystery': 797,\n",
       " 'doubt': 798,\n",
       " 'fantastic': 799,\n",
       " 'kept': 800,\n",
       " 'nearly': 801,\n",
       " 'feels': 802,\n",
       " 'subject': 803,\n",
       " 'okay': 804,\n",
       " 'viewing': 805,\n",
       " 'elements': 806,\n",
       " 'check': 807,\n",
       " 'oscar': 808,\n",
       " 'realistic': 809,\n",
       " 'points': 810,\n",
       " 'means': 811,\n",
       " 'greatest': 812,\n",
       " 'herself': 813,\n",
       " 'parents': 814,\n",
       " 'famous': 815,\n",
       " 'imagine': 816,\n",
       " 'rent': 817,\n",
       " 'viewers': 818,\n",
       " 'crime': 819,\n",
       " 'richard': 820,\n",
       " 'form': 821,\n",
       " 'peter': 822,\n",
       " 'actual': 823,\n",
       " 'lady': 824,\n",
       " 'general': 825,\n",
       " 'dog': 826,\n",
       " 'follow': 827,\n",
       " 'believable': 828,\n",
       " 'period': 829,\n",
       " 'red': 830,\n",
       " 'move': 831,\n",
       " 'brought': 832,\n",
       " 'material': 833,\n",
       " 'forget': 834,\n",
       " 'somehow': 835,\n",
       " 'begins': 836,\n",
       " 're': 837,\n",
       " 'reviews': 838,\n",
       " 'animation': 839,\n",
       " 'paul': 840,\n",
       " \"you've\": 841,\n",
       " 'leads': 842,\n",
       " 'weak': 843,\n",
       " 'figure': 844,\n",
       " 'surprise': 845,\n",
       " 'sit': 846,\n",
       " 'hear': 847,\n",
       " 'average': 848,\n",
       " 'open': 849,\n",
       " 'sequences': 850,\n",
       " 'killing': 851,\n",
       " 'atmosphere': 852,\n",
       " 'eventually': 853,\n",
       " 'learn': 854,\n",
       " 'tom': 855,\n",
       " 'premise': 856,\n",
       " '20': 857,\n",
       " 'wait': 858,\n",
       " 'sci': 859,\n",
       " 'deep': 860,\n",
       " 'fi': 861,\n",
       " 'expected': 862,\n",
       " 'whatever': 863,\n",
       " 'indeed': 864,\n",
       " 'particular': 865,\n",
       " 'lame': 866,\n",
       " 'poorly': 867,\n",
       " 'note': 868,\n",
       " 'imdb': 869,\n",
       " 'dance': 870,\n",
       " 'shame': 871,\n",
       " 'situation': 872,\n",
       " 'third': 873,\n",
       " 'box': 874,\n",
       " 'york': 875,\n",
       " 'truth': 876,\n",
       " 'decided': 877,\n",
       " 'free': 878,\n",
       " 'hot': 879,\n",
       " \"who's\": 880,\n",
       " 'difficult': 881,\n",
       " 'needed': 882,\n",
       " 'season': 883,\n",
       " 'acted': 884,\n",
       " 'leaves': 885,\n",
       " 'unless': 886,\n",
       " 'possibly': 887,\n",
       " 'emotional': 888,\n",
       " 'romance': 889,\n",
       " 'sexual': 890,\n",
       " 'gay': 891,\n",
       " 'boys': 892,\n",
       " 'footage': 893,\n",
       " 'write': 894,\n",
       " 'western': 895,\n",
       " 'credits': 896,\n",
       " 'forced': 897,\n",
       " 'doctor': 898,\n",
       " 'became': 899,\n",
       " 'reading': 900,\n",
       " 'memorable': 901,\n",
       " 'otherwise': 902,\n",
       " 'de': 903,\n",
       " 'begin': 904,\n",
       " 'crew': 905,\n",
       " 'air': 906,\n",
       " 'question': 907,\n",
       " 'society': 908,\n",
       " 'meet': 909,\n",
       " 'male': 910,\n",
       " \"let's\": 911,\n",
       " 'meets': 912,\n",
       " 'plus': 913,\n",
       " 'cheesy': 914,\n",
       " 'hands': 915,\n",
       " 'superb': 916,\n",
       " 'screenplay': 917,\n",
       " 'beauty': 918,\n",
       " 'interested': 919,\n",
       " 'street': 920,\n",
       " 'features': 921,\n",
       " 'whom': 922,\n",
       " 'masterpiece': 923,\n",
       " 'perfectly': 924,\n",
       " 'laughs': 925,\n",
       " 'stage': 926,\n",
       " 'nature': 927,\n",
       " 'effect': 928,\n",
       " 'forward': 929,\n",
       " 'comment': 930,\n",
       " 'nor': 931,\n",
       " 'previous': 932,\n",
       " 'sounds': 933,\n",
       " 'badly': 934,\n",
       " 'e': 935,\n",
       " 'japanese': 936,\n",
       " 'weird': 937,\n",
       " 'island': 938,\n",
       " 'inside': 939,\n",
       " 'personal': 940,\n",
       " 'quickly': 941,\n",
       " 'total': 942,\n",
       " 'keeps': 943,\n",
       " 'towards': 944,\n",
       " 'america': 945,\n",
       " 'result': 946,\n",
       " 'crazy': 947,\n",
       " 'battle': 948,\n",
       " 'worked': 949,\n",
       " 'incredibly': 950,\n",
       " 'setting': 951,\n",
       " 'background': 952,\n",
       " 'earlier': 953,\n",
       " 'mess': 954,\n",
       " 'cop': 955,\n",
       " 'writers': 956,\n",
       " 'fire': 957,\n",
       " 'copy': 958,\n",
       " 'realize': 959,\n",
       " 'dumb': 960,\n",
       " 'unique': 961,\n",
       " 'powerful': 962,\n",
       " 'mark': 963,\n",
       " 'lee': 964,\n",
       " 'business': 965,\n",
       " 'rate': 966,\n",
       " 'older': 967,\n",
       " 'dramatic': 968,\n",
       " 'pay': 969,\n",
       " 'following': 970,\n",
       " 'girlfriend': 971,\n",
       " 'directors': 972,\n",
       " 'joke': 973,\n",
       " 'plenty': 974,\n",
       " 'directing': 975,\n",
       " 'various': 976,\n",
       " 'baby': 977,\n",
       " 'creepy': 978,\n",
       " 'appear': 979,\n",
       " 'development': 980,\n",
       " 'brings': 981,\n",
       " 'front': 982,\n",
       " 'dream': 983,\n",
       " 'ask': 984,\n",
       " 'water': 985,\n",
       " 'admit': 986,\n",
       " 'rich': 987,\n",
       " 'bill': 988,\n",
       " 'apart': 989,\n",
       " 'joe': 990,\n",
       " 'political': 991,\n",
       " 'fairly': 992,\n",
       " 'leading': 993,\n",
       " 'reasons': 994,\n",
       " 'portrayed': 995,\n",
       " 'spent': 996,\n",
       " 'telling': 997,\n",
       " 'cover': 998,\n",
       " 'outside': 999,\n",
       " 'fighting': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124253\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary_dataset=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = numpy.zeros(( size_of_vocabulary_dataset , 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in tokenizer.word_index.items():\n",
    "    #print(i,word)\n",
    "    if word in vocab_word2vec :\n",
    "        embedding_matrix[i] =  word2vec[word]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-pairing dataset for training , validation and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debugging meassage -   negative  12500  postivie  12500\n",
      "debugging message  types  <class 'NoneType'> <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "[x_train,y_train,x_val,y_val] = split_train_val( x_train_val , y_train_val , 0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sq = tokenizer.texts_to_sequences( x_train )\n",
    "x_val_sq = tokenizer.texts_to_sequences( x_val )\n",
    "x_test_sq = tokenizer.texts_to_sequences( x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_test_val = []\n",
    "for i in range( len(x_train_sq) ) :\n",
    "    all_train_test_val.append( len(x_train_sq[i]) )\n",
    "for i in range( len(x_val_sq) ) :\n",
    "    all_train_test_val.append( len(x_val_sq[i]) )\n",
    "for i in range( len(x_test_sq) ) :\n",
    "    all_train_test_val.append( len(x_test_sq[i]) )\n",
    "maximum = max(all_train_test_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2493"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "positive sample  8750  negative sample  8750\n",
      "0 20 0.0008 0.0005714285714285715 0.0006857142857142857\n",
      "1 40 0.005714285714285714 0.007542857142857143 0.006628571428571429\n",
      "2 60 0.03577142857142857 0.046285714285714284 0.04102857142857143\n",
      "3 80 0.06754285714285714 0.0888 0.07817142857142857\n",
      "4 100 0.10274285714285715 0.12708571428571427 0.11491428571428572\n",
      "5 120 0.17177142857142857 0.20125714285714286 0.18651428571428572\n",
      "6 140 0.3144 0.32994285714285715 0.32217142857142855\n",
      "7 160 0.4268571428571429 0.43074285714285715 0.4288\n",
      "8 180 0.5086857142857143 0.5107428571428572 0.5097142857142857\n",
      "9 200 0.5802285714285714 0.5723428571428572 0.5762857142857143\n",
      "10 220 0.6332571428571429 0.62 0.6266285714285714\n",
      "11 240 0.6746285714285715 0.6628571428571428 0.6687428571428572\n",
      "12 260 0.7125714285714285 0.7011428571428572 0.7068571428571429\n",
      "13 280 0.7457142857142857 0.7305142857142857 0.7381142857142857\n",
      "14 300 0.7723428571428571 0.7566857142857143 0.7645142857142857\n",
      "15 320 0.7955428571428571 0.7804571428571428 0.788\n",
      "16 340 0.8154285714285714 0.8038857142857143 0.8096571428571429\n",
      "17 360 0.8344 0.8226285714285714 0.8285142857142858\n",
      "18 380 0.8529142857142857 0.8408 0.8468571428571429\n",
      "19 400 0.8682285714285715 0.8530285714285715 0.8606285714285714\n",
      "20 420 0.8821714285714286 0.8666285714285714 0.8744\n",
      "21 440 0.8932571428571429 0.8794285714285714 0.8863428571428571\n",
      "22 460 0.9037714285714286 0.8899428571428571 0.8968571428571429\n",
      "23 480 0.9130285714285714 0.9003428571428571 0.9066857142857143\n",
      "24 500 0.9221714285714285 0.9083428571428571 0.9152571428571429\n",
      "25 520 0.9302857142857143 0.9156571428571428 0.9229714285714286\n",
      "26 540 0.9372571428571429 0.924 0.9306285714285715\n",
      "27 560 0.9427428571428571 0.9296 0.9361714285714285\n",
      "28 580 0.948 0.9356571428571429 0.9418285714285715\n",
      "29 600 0.9542857142857143 0.9418285714285715 0.9480571428571428\n",
      "30 620 0.9580571428571428 0.9460571428571428 0.9520571428571428\n",
      "31 640 0.9620571428571428 0.9524571428571429 0.9572571428571428\n",
      "32 660 0.9654857142857143 0.9561142857142857 0.9608\n",
      "33 680 0.9684571428571429 0.9594285714285714 0.9639428571428571\n",
      "34 700 0.9707428571428571 0.9638857142857142 0.9673142857142857\n",
      "35 720 0.9737142857142858 0.9675428571428571 0.9706285714285714\n",
      "36 740 0.976 0.9712 0.9736\n",
      "37 760 0.9785142857142857 0.9745142857142857 0.9765142857142857\n",
      "38 780 0.9805714285714285 0.9763428571428572 0.9784571428571428\n",
      "39 800 0.9826285714285714 0.9789714285714286 0.9808\n",
      "40 820 0.9845714285714285 0.9811428571428571 0.9828571428571429\n",
      "41 840 0.9861714285714286 0.9836571428571429 0.9849142857142857\n",
      "42 860 0.9875428571428572 0.9846857142857143 0.9861142857142857\n",
      "43 880 0.9896 0.9859428571428571 0.9877714285714285\n",
      "44 900 0.9902857142857143 0.9870857142857142 0.9886857142857143\n",
      "45 920 0.9912 0.988 0.9896\n",
      "46 940 0.9921142857142857 0.9897142857142858 0.9909142857142857\n",
      "47 960 0.9934857142857143 0.9912 0.9923428571428572\n",
      "48 980 0.9944 0.9930285714285715 0.9937142857142857\n",
      "49 1000 0.9957714285714285 0.9949714285714286 0.9953714285714286\n",
      "50 1020 0.9980571428571429 0.9978285714285714 0.9979428571428571\n",
      "51 1040 0.9993142857142857 0.9985142857142857 0.9989142857142858\n",
      "52 1060 0.9994285714285714 0.9985142857142857 0.9989714285714286\n",
      "53 1080 0.9994285714285714 0.9986285714285714 0.9990285714285714\n",
      "54 1100 0.9995428571428572 0.9989714285714286 0.9992571428571428\n",
      "55 1120 0.9995428571428572 0.9990857142857142 0.9993142857142857\n",
      "56 1140 0.9995428571428572 0.9990857142857142 0.9993142857142857\n",
      "57 1160 0.9995428571428572 0.9990857142857142 0.9993142857142857\n",
      "58 1180 0.9995428571428572 0.9992 0.9993714285714286\n",
      "59 1200 0.9995428571428572 0.9992 0.9993714285714286\n",
      "60 1220 0.9995428571428572 0.9993142857142857 0.9994285714285714\n",
      "61 1240 0.9996571428571429 0.9993142857142857 0.9994857142857143\n",
      "62 1260 0.9996571428571429 0.9993142857142857 0.9994857142857143\n",
      "63 1280 0.9996571428571429 0.9993142857142857 0.9994857142857143\n",
      "64 1300 0.9997714285714285 0.9993142857142857 0.9995428571428572\n",
      "65 1320 0.9997714285714285 0.9994285714285714 0.9996\n",
      "66 1340 0.9997714285714285 0.9994285714285714 0.9996\n",
      "67 1360 0.9997714285714285 0.9994285714285714 0.9996\n",
      "68 1380 0.9997714285714285 0.9994285714285714 0.9996\n",
      "69 1400 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "70 1420 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "71 1440 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "72 1460 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "73 1480 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "74 1500 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "75 1520 0.9998857142857143 0.9994285714285714 0.9996571428571429\n",
      "76 1540 1.0 0.9994285714285714 0.9997142857142857\n",
      "77 1560 1.0 0.9995428571428572 0.9997714285714285\n",
      "78 1580 1.0 0.9995428571428572 0.9997714285714285\n",
      "79 1600 1.0 0.9995428571428572 0.9997714285714285\n",
      "80 1620 1.0 0.9995428571428572 0.9997714285714285\n",
      "81 1640 1.0 0.9995428571428572 0.9997714285714285\n",
      "82 1660 1.0 0.9995428571428572 0.9997714285714285\n",
      "83 1680 1.0 0.9995428571428572 0.9997714285714285\n",
      "84 1700 1.0 0.9995428571428572 0.9997714285714285\n",
      "85 1720 1.0 0.9995428571428572 0.9997714285714285\n",
      "86 1740 1.0 0.9996571428571429 0.9998285714285714\n",
      "87 1760 1.0 0.9996571428571429 0.9998285714285714\n",
      "88 1780 1.0 0.9996571428571429 0.9998285714285714\n",
      "89 1800 1.0 0.9996571428571429 0.9998285714285714\n",
      "90 1820 1.0 0.9996571428571429 0.9998285714285714\n",
      "91 1840 1.0 0.9996571428571429 0.9998285714285714\n",
      "92 1860 1.0 0.9998857142857143 0.9999428571428571\n",
      "93 1880 1.0 0.9998857142857143 0.9999428571428571\n",
      "94 1900 1.0 0.9998857142857143 0.9999428571428571\n",
      "95 1920 1.0 0.9998857142857143 0.9999428571428571\n",
      "96 1940 1.0 0.9998857142857143 0.9999428571428571\n",
      "97 1960 1.0 0.9998857142857143 0.9999428571428571\n",
      "98 1980 1.0 0.9998857142857143 0.9999428571428571\n",
      "99 2000 1.0 0.9998857142857143 0.9999428571428571\n",
      "100 2020 1.0 0.9998857142857143 0.9999428571428571\n",
      "101 2040 1.0 0.9998857142857143 0.9999428571428571\n",
      "102 2060 1.0 0.9998857142857143 0.9999428571428571\n",
      "103 2080 1.0 0.9998857142857143 0.9999428571428571\n",
      "104 2100 1.0 0.9998857142857143 0.9999428571428571\n",
      "105 2120 1.0 0.9998857142857143 0.9999428571428571\n",
      "106 2140 1.0 0.9998857142857143 0.9999428571428571\n",
      "107 2160 1.0 0.9998857142857143 0.9999428571428571\n",
      "108 2180 1.0 0.9998857142857143 0.9999428571428571\n",
      "109 2200 1.0 0.9998857142857143 0.9999428571428571\n",
      "110 2220 1.0 0.9998857142857143 0.9999428571428571\n",
      "111 2240 1.0 0.9998857142857143 0.9999428571428571\n",
      "112 2260 1.0 0.9998857142857143 0.9999428571428571\n",
      "113 2280 1.0 0.9998857142857143 0.9999428571428571\n",
      "114 2300 1.0 0.9998857142857143 0.9999428571428571\n",
      "115 2320 1.0 0.9998857142857143 0.9999428571428571\n",
      "116 2340 1.0 0.9998857142857143 0.9999428571428571\n",
      "117 2360 1.0 0.9998857142857143 0.9999428571428571\n",
      "118 2380 1.0 0.9998857142857143 0.9999428571428571\n",
      "119 2400 1.0 0.9998857142857143 0.9999428571428571\n",
      "120 2420 1.0 0.9998857142857143 0.9999428571428571\n",
      "121 2440 1.0 0.9998857142857143 0.9999428571428571\n",
      "122 2460 1.0 0.9998857142857143 0.9999428571428571\n",
      "123 2480 1.0 0.9998857142857143 0.9999428571428571\n",
      "124 2500 1.0 1.0 1.0\n",
      "125 2520 1.0 1.0 1.0\n",
      "126 2540 1.0 1.0 1.0\n",
      "127 2560 1.0 1.0 1.0\n",
      "128 2580 1.0 1.0 1.0\n",
      "129 2600 1.0 1.0 1.0\n",
      "130 2620 1.0 1.0 1.0\n",
      "131 2640 1.0 1.0 1.0\n",
      "132 2660 1.0 1.0 1.0\n",
      "133 2680 1.0 1.0 1.0\n",
      "134 2700 1.0 1.0 1.0\n",
      "135 2720 1.0 1.0 1.0\n",
      "136 2740 1.0 1.0 1.0\n",
      "137 2760 1.0 1.0 1.0\n",
      "138 2780 1.0 1.0 1.0\n",
      "139 2800 1.0 1.0 1.0\n",
      "140 2820 1.0 1.0 1.0\n",
      "141 2840 1.0 1.0 1.0\n",
      "142 2860 1.0 1.0 1.0\n",
      "143 2880 1.0 1.0 1.0\n",
      "144 2900 1.0 1.0 1.0\n",
      "145 2920 1.0 1.0 1.0\n",
      "146 2940 1.0 1.0 1.0\n",
      "147 2960 1.0 1.0 1.0\n",
      "148 2980 1.0 1.0 1.0\n",
      "149 3000 1.0 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[frq_train_n,frq_train_p,frq_train_t] = visualize(x_train_sq, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "positive sample  3750  negative sample  3750\n",
      "0 20 0.0005333333333333334 0.0 0.0002666666666666667\n",
      "1 40 0.005066666666666666 0.0088 0.006933333333333333\n",
      "2 60 0.028533333333333334 0.044533333333333334 0.036533333333333334\n",
      "3 80 0.06213333333333333 0.08373333333333334 0.07293333333333334\n",
      "4 100 0.09706666666666666 0.1192 0.10813333333333333\n",
      "5 120 0.1736 0.1952 0.1844\n",
      "6 140 0.31653333333333333 0.3224 0.3194666666666667\n",
      "7 160 0.41786666666666666 0.42533333333333334 0.4216\n",
      "8 180 0.5029333333333333 0.5050666666666667 0.504\n",
      "9 200 0.5706666666666667 0.5594666666666667 0.5650666666666667\n",
      "10 220 0.6245333333333334 0.6146666666666667 0.6196\n",
      "11 240 0.6704 0.6578666666666667 0.6641333333333334\n",
      "12 260 0.7096 0.6949333333333333 0.7022666666666667\n",
      "13 280 0.7442666666666666 0.7261333333333333 0.7352\n",
      "14 300 0.7706666666666667 0.7528 0.7617333333333334\n",
      "15 320 0.7954666666666667 0.7805333333333333 0.788\n",
      "16 340 0.8202666666666667 0.7986666666666666 0.8094666666666667\n",
      "17 360 0.8421333333333333 0.8173333333333334 0.8297333333333333\n",
      "18 380 0.8589333333333333 0.8354666666666667 0.8472\n",
      "19 400 0.8712 0.8501333333333333 0.8606666666666667\n",
      "20 420 0.8866666666666667 0.8608 0.8737333333333334\n",
      "21 440 0.8954666666666666 0.8749333333333333 0.8852\n",
      "22 460 0.9072 0.8861333333333333 0.8966666666666666\n",
      "23 480 0.9157333333333333 0.8970666666666667 0.9064\n",
      "24 500 0.9250666666666667 0.9082666666666667 0.9166666666666666\n",
      "25 520 0.932 0.9168 0.9244\n",
      "26 540 0.9368 0.9258666666666666 0.9313333333333333\n",
      "27 560 0.9434666666666667 0.932 0.9377333333333333\n",
      "28 580 0.9461333333333334 0.9384 0.9422666666666667\n",
      "29 600 0.9528 0.9437333333333333 0.9482666666666667\n",
      "30 620 0.9576 0.948 0.9528\n",
      "31 640 0.9605333333333334 0.9538666666666666 0.9572\n",
      "32 660 0.9626666666666667 0.9594666666666667 0.9610666666666666\n",
      "33 680 0.9653333333333334 0.9632 0.9642666666666667\n",
      "34 700 0.968 0.9664 0.9672\n",
      "35 720 0.9698666666666667 0.9688 0.9693333333333334\n",
      "36 740 0.972 0.9717333333333333 0.9718666666666667\n",
      "37 760 0.9749333333333333 0.9733333333333334 0.9741333333333333\n",
      "38 780 0.976 0.9757333333333333 0.9758666666666667\n",
      "39 800 0.9789333333333333 0.9781333333333333 0.9785333333333334\n",
      "40 820 0.9805333333333334 0.9810666666666666 0.9808\n",
      "41 840 0.9824 0.9824 0.9824\n",
      "42 860 0.9848 0.9834666666666667 0.9841333333333333\n",
      "43 880 0.9864 0.9856 0.986\n",
      "44 900 0.9874666666666667 0.9874666666666667 0.9874666666666667\n",
      "45 920 0.9896 0.9898666666666667 0.9897333333333334\n",
      "46 940 0.9904 0.9906666666666667 0.9905333333333334\n",
      "47 960 0.9904 0.9917333333333334 0.9910666666666667\n",
      "48 980 0.992 0.9930666666666667 0.9925333333333334\n",
      "49 1000 0.9949333333333333 0.9949333333333333 0.9949333333333333\n",
      "50 1020 0.9973333333333333 0.9973333333333333 0.9973333333333333\n",
      "51 1040 0.9984 0.9984 0.9984\n",
      "52 1060 0.9986666666666667 0.9986666666666667 0.9986666666666667\n",
      "53 1080 0.9986666666666667 0.9986666666666667 0.9986666666666667\n",
      "54 1100 0.9989333333333333 0.9986666666666667 0.9988\n",
      "55 1120 0.9992 0.9986666666666667 0.9989333333333333\n",
      "56 1140 0.9992 0.9986666666666667 0.9989333333333333\n",
      "57 1160 0.9992 0.9986666666666667 0.9989333333333333\n",
      "58 1180 0.9992 0.9989333333333333 0.9990666666666667\n",
      "59 1200 0.9992 0.9989333333333333 0.9990666666666667\n",
      "60 1220 0.9992 0.9989333333333333 0.9990666666666667\n",
      "61 1240 0.9992 0.9992 0.9992\n",
      "62 1260 0.9992 0.9992 0.9992\n",
      "63 1280 0.9992 0.9992 0.9992\n",
      "64 1300 0.9992 0.9994666666666666 0.9993333333333333\n",
      "65 1320 0.9992 0.9994666666666666 0.9993333333333333\n",
      "66 1340 0.9994666666666666 0.9994666666666666 0.9994666666666666\n",
      "67 1360 0.9994666666666666 0.9994666666666666 0.9994666666666666\n",
      "68 1380 0.9994666666666666 0.9994666666666666 0.9994666666666666\n",
      "69 1400 0.9994666666666666 0.9994666666666666 0.9994666666666666\n",
      "70 1420 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "71 1440 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "72 1460 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "73 1480 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "74 1500 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "75 1520 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "76 1540 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "77 1560 0.9997333333333334 0.9997333333333334 0.9997333333333334\n",
      "78 1580 1.0 0.9997333333333334 0.9998666666666667\n",
      "79 1600 1.0 0.9997333333333334 0.9998666666666667\n",
      "80 1620 1.0 0.9997333333333334 0.9998666666666667\n",
      "81 1640 1.0 1.0 1.0\n",
      "82 1660 1.0 1.0 1.0\n",
      "83 1680 1.0 1.0 1.0\n",
      "84 1700 1.0 1.0 1.0\n",
      "85 1720 1.0 1.0 1.0\n",
      "86 1740 1.0 1.0 1.0\n",
      "87 1760 1.0 1.0 1.0\n",
      "88 1780 1.0 1.0 1.0\n",
      "89 1800 1.0 1.0 1.0\n",
      "90 1820 1.0 1.0 1.0\n",
      "91 1840 1.0 1.0 1.0\n",
      "92 1860 1.0 1.0 1.0\n",
      "93 1880 1.0 1.0 1.0\n",
      "94 1900 1.0 1.0 1.0\n",
      "95 1920 1.0 1.0 1.0\n",
      "96 1940 1.0 1.0 1.0\n",
      "97 1960 1.0 1.0 1.0\n",
      "98 1980 1.0 1.0 1.0\n",
      "99 2000 1.0 1.0 1.0\n",
      "100 2020 1.0 1.0 1.0\n",
      "101 2040 1.0 1.0 1.0\n",
      "102 2060 1.0 1.0 1.0\n",
      "103 2080 1.0 1.0 1.0\n",
      "104 2100 1.0 1.0 1.0\n",
      "105 2120 1.0 1.0 1.0\n",
      "106 2140 1.0 1.0 1.0\n",
      "107 2160 1.0 1.0 1.0\n",
      "108 2180 1.0 1.0 1.0\n",
      "109 2200 1.0 1.0 1.0\n",
      "110 2220 1.0 1.0 1.0\n",
      "111 2240 1.0 1.0 1.0\n",
      "112 2260 1.0 1.0 1.0\n",
      "113 2280 1.0 1.0 1.0\n",
      "114 2300 1.0 1.0 1.0\n",
      "115 2320 1.0 1.0 1.0\n",
      "116 2340 1.0 1.0 1.0\n",
      "117 2360 1.0 1.0 1.0\n",
      "118 2380 1.0 1.0 1.0\n",
      "119 2400 1.0 1.0 1.0\n",
      "120 2420 1.0 1.0 1.0\n",
      "121 2440 1.0 1.0 1.0\n",
      "122 2460 1.0 1.0 1.0\n",
      "123 2480 1.0 1.0 1.0\n",
      "124 2500 1.0 1.0 1.0\n",
      "125 2520 1.0 1.0 1.0\n",
      "126 2540 1.0 1.0 1.0\n",
      "127 2560 1.0 1.0 1.0\n",
      "128 2580 1.0 1.0 1.0\n",
      "129 2600 1.0 1.0 1.0\n",
      "130 2620 1.0 1.0 1.0\n",
      "131 2640 1.0 1.0 1.0\n",
      "132 2660 1.0 1.0 1.0\n",
      "133 2680 1.0 1.0 1.0\n",
      "134 2700 1.0 1.0 1.0\n",
      "135 2720 1.0 1.0 1.0\n",
      "136 2740 1.0 1.0 1.0\n",
      "137 2760 1.0 1.0 1.0\n",
      "138 2780 1.0 1.0 1.0\n",
      "139 2800 1.0 1.0 1.0\n",
      "140 2820 1.0 1.0 1.0\n",
      "141 2840 1.0 1.0 1.0\n",
      "142 2860 1.0 1.0 1.0\n",
      "143 2880 1.0 1.0 1.0\n",
      "144 2900 1.0 1.0 1.0\n",
      "145 2920 1.0 1.0 1.0\n",
      "146 2940 1.0 1.0 1.0\n",
      "147 2960 1.0 1.0 1.0\n",
      "148 2980 1.0 1.0 1.0\n",
      "149 3000 1.0 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[frq_train_n,frq_train_p,frq_train_t] = visualize(x_val_sq, y_val )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "positive sample  12500  negative sample  12500\n",
      "0 20 0.00048 0.00064 0.00056\n",
      "1 40 0.0072 0.00776 0.00748\n",
      "2 60 0.0404 0.04496 0.04268\n",
      "3 80 0.07296 0.0904 0.08168\n",
      "4 100 0.10912 0.12848 0.1188\n",
      "5 120 0.18392 0.20664 0.19528\n",
      "6 140 0.3168 0.34064 0.32872\n",
      "7 160 0.4236 0.44136 0.43248\n",
      "8 180 0.51 0.52416 0.51708\n",
      "9 200 0.57736 0.58848 0.58292\n",
      "10 220 0.63272 0.64296 0.63784\n",
      "11 240 0.68016 0.68536 0.68276\n",
      "12 260 0.71456 0.72056 0.71756\n",
      "13 280 0.74576 0.74752 0.74664\n",
      "14 300 0.77528 0.7744 0.77484\n",
      "15 320 0.80048 0.79848 0.79948\n",
      "16 340 0.82152 0.81904 0.82028\n",
      "17 360 0.8396 0.83584 0.83772\n",
      "18 380 0.85784 0.85104 0.85444\n",
      "19 400 0.87336 0.86512 0.86924\n",
      "20 420 0.88736 0.8768 0.88208\n",
      "21 440 0.89976 0.88792 0.89384\n",
      "22 460 0.90984 0.898 0.90392\n",
      "23 480 0.91968 0.90712 0.9134\n",
      "24 500 0.926 0.91528 0.92064\n",
      "25 520 0.93208 0.92312 0.9276\n",
      "26 540 0.93864 0.93096 0.9348\n",
      "27 560 0.94496 0.93712 0.94104\n",
      "28 580 0.95024 0.94376 0.947\n",
      "29 600 0.9548 0.94888 0.95184\n",
      "30 620 0.95848 0.95408 0.95628\n",
      "31 640 0.9624 0.95816 0.96028\n",
      "32 660 0.96576 0.96192 0.96384\n",
      "33 680 0.96888 0.96504 0.96696\n",
      "34 700 0.97224 0.96768 0.96996\n",
      "35 720 0.97456 0.9708 0.97268\n",
      "36 740 0.97656 0.97384 0.9752\n",
      "37 760 0.97888 0.97608 0.97748\n",
      "38 780 0.98096 0.97864 0.9798\n",
      "39 800 0.9832 0.98024 0.98172\n",
      "40 820 0.9852 0.98232 0.98376\n",
      "41 840 0.9868 0.98408 0.98544\n",
      "42 860 0.98808 0.98552 0.9868\n",
      "43 880 0.98896 0.9872 0.98808\n",
      "44 900 0.98992 0.9884 0.98916\n",
      "45 920 0.99144 0.98952 0.99048\n",
      "46 940 0.99288 0.9908 0.99184\n",
      "47 960 0.9936 0.99208 0.99284\n",
      "48 980 0.9948 0.99384 0.99432\n",
      "49 1000 0.9964 0.9952 0.9958\n",
      "50 1020 0.99872 0.9984 0.99856\n",
      "51 1040 0.99968 0.99928 0.99948\n",
      "52 1060 0.99968 0.99928 0.99948\n",
      "53 1080 0.99968 0.99936 0.99952\n",
      "54 1100 0.99984 0.99936 0.9996\n",
      "55 1120 1.0 0.99944 0.99972\n",
      "56 1140 1.0 0.99944 0.99972\n",
      "57 1160 1.0 0.99944 0.99972\n",
      "58 1180 1.0 0.99944 0.99972\n",
      "59 1200 1.0 0.9996 0.9998\n",
      "60 1220 1.0 0.9996 0.9998\n",
      "61 1240 1.0 0.9996 0.9998\n",
      "62 1260 1.0 0.9996 0.9998\n",
      "63 1280 1.0 0.9996 0.9998\n",
      "64 1300 1.0 0.9996 0.9998\n",
      "65 1320 1.0 0.9996 0.9998\n",
      "66 1340 1.0 0.9996 0.9998\n",
      "67 1360 1.0 0.9996 0.9998\n",
      "68 1380 1.0 0.9996 0.9998\n",
      "69 1400 1.0 0.99968 0.99984\n",
      "70 1420 1.0 0.99968 0.99984\n",
      "71 1440 1.0 0.99968 0.99984\n",
      "72 1460 1.0 0.99968 0.99984\n",
      "73 1480 1.0 0.99968 0.99984\n",
      "74 1500 1.0 0.99968 0.99984\n",
      "75 1520 1.0 0.99968 0.99984\n",
      "76 1540 1.0 0.99968 0.99984\n",
      "77 1560 1.0 0.99968 0.99984\n",
      "78 1580 1.0 0.99968 0.99984\n",
      "79 1600 1.0 0.99968 0.99984\n",
      "80 1620 1.0 0.99968 0.99984\n",
      "81 1640 1.0 0.99968 0.99984\n",
      "82 1660 1.0 0.99968 0.99984\n",
      "83 1680 1.0 0.99968 0.99984\n",
      "84 1700 1.0 0.99968 0.99984\n",
      "85 1720 1.0 0.99968 0.99984\n",
      "86 1740 1.0 0.99968 0.99984\n",
      "87 1760 1.0 0.99976 0.99988\n",
      "88 1780 1.0 0.99976 0.99988\n",
      "89 1800 1.0 0.99976 0.99988\n",
      "90 1820 1.0 0.99976 0.99988\n",
      "91 1840 1.0 0.99976 0.99988\n",
      "92 1860 1.0 0.99976 0.99988\n",
      "93 1880 1.0 0.99976 0.99988\n",
      "94 1900 1.0 0.99976 0.99988\n",
      "95 1920 1.0 0.99976 0.99988\n",
      "96 1940 1.0 0.99976 0.99988\n",
      "97 1960 1.0 0.99976 0.99988\n",
      "98 1980 1.0 0.99976 0.99988\n",
      "99 2000 1.0 0.99976 0.99988\n",
      "100 2020 1.0 0.99976 0.99988\n",
      "101 2040 1.0 0.99976 0.99988\n",
      "102 2060 1.0 0.99976 0.99988\n",
      "103 2080 1.0 0.99976 0.99988\n",
      "104 2100 1.0 0.99976 0.99988\n",
      "105 2120 1.0 0.99976 0.99988\n",
      "106 2140 1.0 0.99976 0.99988\n",
      "107 2160 1.0 0.99984 0.99992\n",
      "108 2180 1.0 0.99992 0.99996\n",
      "109 2200 1.0 0.99992 0.99996\n",
      "110 2220 1.0 0.99992 0.99996\n",
      "111 2240 1.0 0.99992 0.99996\n",
      "112 2260 1.0 0.99992 0.99996\n",
      "113 2280 1.0 0.99992 0.99996\n",
      "114 2300 1.0 0.99992 0.99996\n",
      "115 2320 1.0 0.99992 0.99996\n",
      "116 2340 1.0 1.0 1.0\n",
      "117 2360 1.0 1.0 1.0\n",
      "118 2380 1.0 1.0 1.0\n",
      "119 2400 1.0 1.0 1.0\n",
      "120 2420 1.0 1.0 1.0\n",
      "121 2440 1.0 1.0 1.0\n",
      "122 2460 1.0 1.0 1.0\n",
      "123 2480 1.0 1.0 1.0\n",
      "124 2500 1.0 1.0 1.0\n",
      "125 2520 1.0 1.0 1.0\n",
      "126 2540 1.0 1.0 1.0\n",
      "127 2560 1.0 1.0 1.0\n",
      "128 2580 1.0 1.0 1.0\n",
      "129 2600 1.0 1.0 1.0\n",
      "130 2620 1.0 1.0 1.0\n",
      "131 2640 1.0 1.0 1.0\n",
      "132 2660 1.0 1.0 1.0\n",
      "133 2680 1.0 1.0 1.0\n",
      "134 2700 1.0 1.0 1.0\n",
      "135 2720 1.0 1.0 1.0\n",
      "136 2740 1.0 1.0 1.0\n",
      "137 2760 1.0 1.0 1.0\n",
      "138 2780 1.0 1.0 1.0\n",
      "139 2800 1.0 1.0 1.0\n",
      "140 2820 1.0 1.0 1.0\n",
      "141 2840 1.0 1.0 1.0\n",
      "142 2860 1.0 1.0 1.0\n",
      "143 2880 1.0 1.0 1.0\n",
      "144 2900 1.0 1.0 1.0\n",
      "145 2920 1.0 1.0 1.0\n",
      "146 2940 1.0 1.0 1.0\n",
      "147 2960 1.0 1.0 1.0\n",
      "148 2980 1.0 1.0 1.0\n",
      "149 3000 1.0 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[frq_train_n,frq_train_p,frq_train_t] = visualize(x_test_sq, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)) :\n",
    "    y_train[i] = float(y_train[i])\n",
    "for i in range(len(y_val)) :\n",
    "    y_val[i] = float(y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1000\n",
    "x_train_sq_pd = pad_sequences( x_train_sq , maxlen = threshold )\n",
    "x_val_sq_pd = pad_sequences( x_val_sq , maxlen = threshold )\n",
    "x_test_sq_pd = pad_sequences( x_test_sq , maxlen = threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shallow vanila RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         37275900  \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                23360     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,299,325\n",
      "Trainable params: 23,425\n",
      "Non-trainable params: 37,275,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "model.add( SimpleRNN ( 64 , activation = 'sigmoid' ) )\n",
    "model.add( Dense( 1 , activation = 'sigmoid' ) )\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_shallow_VRNN.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 140s 8ms/step - loss: 0.6769 - acc: 0.5663 - val_loss: 0.6606 - val_acc: 0.6035\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60347, saving model to best_model_shallow_VRNN.h\n",
      "Epoch 2/10\n",
      "17408/17500 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.6212"
     ]
    }
   ],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_shallow_VRNN.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",test_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP VANILA RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "model.add( SimpleRNN ( 64 , activation = 'tanh' , retur_sequences = True ) )\n",
    "model.add( SimpleRNN(64,activation = 'tanh') , return_sequences = False )\n",
    "\n",
    "model.add( Dense(32,activation = 'sigmoid' ) )\n",
    "model.add( Dense( 1 , activation = 'sigmoid' ) )\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_deep_VRNN.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_deep_VRNN.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",train_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shallow GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 1000, 300)         37275900  \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 64)                70080     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,346,045\n",
      "Trainable params: 70,145\n",
      "Non-trainable params: 37,275,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "\n",
    "model.add(GRU(64,return_sequences=False,dropout=0.2))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(1,activation='softmax')) \n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_shallow_GRU.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 317s 18ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to best_model_GRU_sh.h\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 321s 18ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 343s 20ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.50000\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 319s 18ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.50000\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 112s 6ms/step\n",
      "7500/7500 [==============================] - 36s 5ms/step\n",
      "25000/25000 [==============================] - 145s 6ms/step\n",
      "train acc  0.7563199996948242\n",
      "val acc  0.7544000148773193\n",
      "test acc  0.7563199996948242\n"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model_shallow_GRU.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",train_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574856877326965"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 1000, 300)         37275900  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 1000, 64)          70080     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,372,861\n",
      "Trainable params: 96,961\n",
      "Non-trainable params: 37,275,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "\n",
    "model.add(GRU(64,return_sequences=True,dropout=0.2))\n",
    "model.add ( GRU(64,return_sequences=False, dropout=0.2) )\n",
    "\n",
    "model.add(Dense(32,activation='softmax')) \n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_deep_GRU.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 501s 29ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to best_model_deep_GRU.h\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 487s 28ms/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "Epoch 3/10\n",
      " 2944/17500 [====>.........................] - ETA: 6:21 - loss: 7.6458 - acc: 0.5014"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-431104e602f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 141s 8ms/step\n",
      "7500/7500 [==============================] - 61s 8ms/step\n",
      "18944/25000 [=====================>........] - ETA: 50s"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model_deep_GRU.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",train_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shallow LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1000, 300)         37275900  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,371,453\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 37,275,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "\n",
    "model.add ( LSTM(64,return_sequences=False) )\n",
    "\n",
    "model.add(Dense(32,activation='sigmoid')) \n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_shallow_LSTM.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 387s 22ms/step - loss: 0.5618 - acc: 0.7078 - val_loss: 0.4348 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81093, saving model to best_model_shallow_LSTM.h\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 373s 21ms/step - loss: 0.4232 - acc: 0.8152 - val_loss: 0.3927 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.81093 to 0.83693, saving model to best_model_shallow_LSTM.h\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 344s 20ms/step - loss: 0.4570 - acc: 0.7981 - val_loss: 0.4109 - val_acc: 0.8271\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83693\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 339s 19ms/step - loss: 0.3831 - acc: 0.8395 - val_loss: 0.7514 - val_acc: 0.7295\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83693\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 338s 19ms/step - loss: 0.4324 - acc: 0.8145 - val_loss: 0.3578 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.83693 to 0.85653, saving model to best_model_shallow_LSTM.h\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 340s 19ms/step - loss: 0.3611 - acc: 0.8524 - val_loss: 0.4434 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.85653\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 333s 19ms/step - loss: 0.3835 - acc: 0.8413 - val_loss: 0.4007 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85653\n",
      "Epoch 8/10\n",
      " 2432/17500 [===>..........................] - ETA: 3:56 - loss: 0.3651 - acc: 0.8483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-431104e602f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 99s 6ms/step\n",
      "7500/7500 [==============================] - 43s 6ms/step\n",
      "25000/25000 [==============================] - 143s 6ms/step\n",
      "train acc  0.8556399941444397\n",
      "val acc  0.8565333485603333\n",
      "test acc  0.8556399941444397\n"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model_shallow_LSTM.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",train_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1000, 300)         37275900  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1000, 64)          93440     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,404,477\n",
      "Trainable params: 128,577\n",
      "Non-trainable params: 37,275,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size_of_vocabulary_dataset,300,weights=[embedding_matrix],input_length= threshold ,trainable=False)) \n",
    "\n",
    "model.add ( LSTM(64,return_sequences=True) )\n",
    "model.add( LSTM(64,return_sequences=False) )\n",
    "\n",
    "model.add(Dense(32,activation='sigmoid')) \n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'] )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model_deep_LSTM.h', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "  768/17500 [>.............................] - ETA: 11:41 - loss: 0.7200 - acc: 0.5260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-431104e602f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_sq_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(numpy.array(x_train_sq_pd),numpy.array(y_train),batch_size=128,epochs=10,validation_data=(numpy.array(x_val_sq_pd),numpy.array(y_val)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_deep_LSTM.h')\n",
    "\n",
    "#evaluation \n",
    "_,train_acc = model.evaluate(x_train_sq_pd,y_train, batch_size=128)\n",
    "_,val_acc = model.evaluate( x_val_sq_pd , y_val , batch_size = 128 )\n",
    "_,test_acc = model.evaluate( x_test_sq_pd , y_test , batch_size=128 )\n",
    "print(\"train acc \",train_acc)\n",
    "print(\"val acc \",val_acc)\n",
    "print(\"test acc \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
